{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are we in SWAN?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working in the right path\n",
    "%cd /eos/project/d/da-and-diffusion-studies/DA_Studies/Simulations/Models/da_sixtrack/for_martin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the libraries\n",
    "import sys\n",
    "!{sys.executable} -m pip install --user sixtrackwrap\n",
    "!export PYTHONPATH=$CERNBOX_HOME/.local/lib/python3.7/site-packages:$PYTHONPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this \"presentation\" only!\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using SixTrackLib for Radial Scans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main technique for extrapolating Dynamic Aperture (\"Dynamic aperture estimates and phase-space distortions in nonlinear betatron motion\" by E. Todesco and M. Giovannozzi) is the Radial Scanning process where, for various initial angular conditions, we scan particles at increasing radial distance from the reference orbit until we find an unstable particle.\n",
    "\n",
    "GPU computing relies heavly on SIMD instruction with no efficient branching allowed. However, SixTrackLib implements various techniques for replacing known lost particles with other particles yet to be tracked, without loosing precious GPU computing power.\n",
    "\n",
    "These efficient implementation allows us to instanciate many complete radial scans on an advanced Nvidia Tesla card without worrying \"too much\" of exploring too deeply an angle and ending up with particles that are lost almost immediatly. With a less efficient implementation, these particles would have become dead weight for an entire computing batch.\n",
    "\n",
    "In this notebook, we display some stabilty plots we have made thanks to SixTrackLib."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base libraries\n",
    "import math\n",
    "import numpy as np\n",
    "import scipy.integrate as integrate\n",
    "from scipy.special import erf\n",
    "import pickle\n",
    "import itertools\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "from numba import njit, prange\n",
    "\n",
    "# Personal libraries\n",
    "#import sixtrackwrap_light as sx\n",
    "import sixtrackwrap as sx\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import matplotlib\n",
    "import matplotlib.ticker as ticker\n",
    "from math import gcd\n",
    "\n",
    "from scipy.special import lambertw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some stability plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath = \"data/\"\n",
    "engine = sx.radial_scanner.load_values(savepath + \"big_scan.pkl\")\n",
    "\n",
    "min_turns = engine.min_time\n",
    "max_turns = engine.max_time\n",
    "n_turn_samples = 500\n",
    "\n",
    "turn_sampling = np.linspace(min_turns, max_turns, n_turn_samples, dtype=np.int_)[::-1]\n",
    "\n",
    "d_r = engine.dr\n",
    "starting_step = engine.starting_step\n",
    "\n",
    "# BASELINE COMPUTING\n",
    "baseline_samples = 33\n",
    "baseline_total_samples = baseline_samples ** 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_preliminary_values = np.linspace(-1.0, 1.0, baseline_samples)\n",
    "alpha_values = np.arccos(alpha_preliminary_values) / 2\n",
    "theta1_values = np.linspace(0.0, np.pi * 2.0, baseline_samples, endpoint=False)\n",
    "theta2_values = np.linspace(0.0, np.pi * 2.0, baseline_samples, endpoint=False)\n",
    "\n",
    "d_preliminar_alpha = alpha_preliminary_values[1] - alpha_preliminary_values[0]\n",
    "d_theta1 = theta1_values[1] - theta1_values[0]\n",
    "d_theta2 = theta2_values[1] - theta2_values[0]\n",
    "\n",
    "alpha_mesh, theta1_mesh, theta2_mesh = np.meshgrid(alpha_values, theta1_values, theta2_values, indexing='ij')\n",
    "\n",
    "alpha_flat = alpha_mesh.flatten()\n",
    "theta1_flat = theta1_mesh.flatten()\n",
    "theta2_flat = theta2_mesh.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc404d60111340109ffb6c8504e09a3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, '$y$ [$\\\\sigma$ units]')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig3, ax3 = plt.subplots()\n",
    "cmap3 = matplotlib.cm.get_cmap('viridis')\n",
    "norm3 = matplotlib.colors.Normalize(vmin=np.log10(turn_sampling[-1]), vmax=np.log10(turn_sampling[0]))\n",
    "fig3.colorbar(matplotlib.cm.ScalarMappable(norm=norm3, cmap=cmap3), label='Number of stable turns considered\\n$[\\\\log_{10}(N_{turns})]$')\n",
    "\n",
    "radiuses = engine.extract_DA(turn_sampling)\n",
    "radiuses = radiuses.reshape((baseline_samples, baseline_samples, baseline_samples, len(turn_sampling)))\n",
    "\n",
    "radiuses = radiuses[:, 0, 0, :]\n",
    "\n",
    "for i in list(range(radiuses.shape[-1]))[::-1]:\n",
    "    value = np.log10(turn_sampling[i] - turn_sampling[-1]) / np.log10(turn_sampling[0] - turn_sampling[-1])\n",
    "    x = radiuses[:,i] * np.cos(alpha_values)\n",
    "    y = radiuses[:,i] * np.sin(alpha_values)\n",
    "    x = np.concatenate(([0], x))\n",
    "    y = np.concatenate(([0], y))\n",
    "    ax3.fill(x, y, c=cmap3(value))\n",
    "\n",
    "ax3.set_title(\"LHC lattice (no bb interaction). Stable region.\")\n",
    "ax3.set_xlabel(\"$x$ [$\\\\sigma$ units]\")\n",
    "ax3.set_ylabel(\"$y$ [$\\\\sigma$ units]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36642eda1021485e8c9451f50aea17d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc33dde21cef477a8e0aa94e4ef9076c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='$\\\\theta_1$ slice index'), IntSlider(value=0, continuous_update=False, max=32), La…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a310de474940400dae65490bf0bc37df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig4 = plt.figure()\n",
    "cmap4 = matplotlib.cm.get_cmap('viridis')\n",
    "norm4 = matplotlib.colors.Normalize(vmin=np.log10(turn_sampling[-1]), vmax=np.log10(turn_sampling[0]))\n",
    "fig4.colorbar(matplotlib.cm.ScalarMappable(norm=norm4, cmap=cmap4), label='Number of stable turns considered\\n$[\\\\log_{10}(N_{turns})]$')\n",
    "\n",
    "\n",
    "def update4(idx1, idx2):\n",
    "    radiuses = engine.extract_DA(turn_sampling)\n",
    "    radiuses = radiuses.reshape((baseline_samples, baseline_samples, baseline_samples, len(turn_sampling)))\n",
    "\n",
    "    fig4.clear()\n",
    "    ax4 = fig4.subplots(1, 2) \n",
    "    fig4.colorbar(matplotlib.cm.ScalarMappable(norm=norm4, cmap=cmap4), label='Number of stable turns considered\\n$[\\\\log_{10}(N_{turns})]$')\n",
    "    radiuses = radiuses[:, idx1, idx2, :]\n",
    "\n",
    "    for i in list(range(radiuses.shape[-1]))[::-1]:\n",
    "        value = np.log10(turn_sampling[i] - turn_sampling[-1]) / np.log10(turn_sampling[0] - turn_sampling[-1])\n",
    "        x = radiuses[:,i] * np.cos(alpha_values) * np.cos(theta1_values[idx1])\n",
    "        px = radiuses[:,i] * np.cos(alpha_values) * np.sin(theta1_values[idx1])\n",
    "        y = radiuses[:,i] * np.sin(alpha_values) * np.cos(theta2_values[idx2])\n",
    "        py = radiuses[:,i] * np.sin(alpha_values) * np.sin(theta2_values[idx2])\n",
    "        x = np.concatenate(([0], x))\n",
    "        px = np.concatenate(([0], px))\n",
    "        y = np.concatenate(([0], y))\n",
    "        py = np.concatenate(([0], py))\n",
    "        ax4[0].fill(x, y, c=cmap4(value))\n",
    "        ax4[1].fill(px, py, c=cmap4(value))\n",
    "\n",
    "    fig4.suptitle(\"LHC lattice (no bb interaction). Stable region.\\n4D view. Slice considered: $(\\\\theta_1={:.2}\\\\pi, \\\\theta_2={:.2}\\\\pi)$\".format(theta1_values[idx1]/np.pi, theta2_values[idx2]/np.pi))\n",
    "    ax4[0].set_xlabel(\"$x$ [$\\\\sigma$ units]\")\n",
    "    ax4[0].set_ylabel(\"$y$ [$\\\\sigma$ units]\")\n",
    "    ax4[1].set_xlabel(\"$px$ [$\\\\sigma$ units]\")\n",
    "    ax4[1].set_ylabel(\"$py$ [$\\\\sigma$ units]\")\n",
    "\n",
    "a=widgets.IntSlider(value=0, min=0, max=len(theta1_values) - 1, step=1, continuous_update=False)\n",
    "b=widgets.IntSlider(value=0, min=0, max=len(theta2_values) - 1, step=1, continuous_update=False)\n",
    "ui = widgets.VBox([\n",
    "    widgets.Label(\"$\\\\theta_1$ slice index\"), a,\n",
    "    widgets.Label(\"$\\\\theta_2$ slice index\"), b])\n",
    "    \n",
    "out = widgets.interactive_output(\n",
    "    update4,\n",
    "    {\"idx1\":a, \"idx2\":b}\n",
    ")\n",
    "\n",
    "display(ui, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring and visualizing 3D samples of DA!\n",
    "\n",
    "This is a rather unfinished interactive plot I (Carlo Emilio) am working on.\n",
    "\n",
    "With this tool, you can (somewhat) visualize the angular dependencies of DA by moving the $\\theta_1$ and $\\theta_2$ sliders and setting up 3D samples of different dimension (the resulting sample is sample_size ** 3 big).\n",
    "\n",
    "What you will then visualize is the evolution of DA with the number of turns, considering different $\\alpha$ angles ($\\alpha$ indicates the central angle of the considered sample).\n",
    "\n",
    "**N.B.: the plotting process requires time, so after moving the sliders you will need to wait a little!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52901e058d66482e96b7a385b43f1d47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97f2b00f7b894bb7a7e7974c73530b1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Number of turn samples to visualize'), IntSlider(value=2, continuous_update=False,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d47f82de2fc451b8866d5992a0eb19b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "cmap = matplotlib.cm.get_cmap('viridis')\n",
    "norm = matplotlib.colors.Normalize(vmin=np.log10(turn_sampling[-1]), vmax=np.log10(turn_sampling[0]))\n",
    "fig.colorbar(matplotlib.cm.ScalarMappable(norm=norm, cmap=cmap), label='Number of stable turns considered\\n$[\\\\log_{10}(N_{turns})]$')\n",
    "\n",
    "radiuses = engine.extract_DA(turn_sampling)\n",
    "radiuses = radiuses.reshape((baseline_samples, baseline_samples, baseline_samples, len(turn_sampling)))\n",
    "\n",
    "@njit\n",
    "def find_nearest(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return idx\n",
    "\n",
    "@njit\n",
    "def take_sample(array, value, size):\n",
    "    assert size % 2 == 0\n",
    "    array = np.asarray(array)\n",
    "    idx = find_nearest(array, value)\n",
    "    if idx < size:\n",
    "        return 0, size\n",
    "    elif idx >= len(array) - size:\n",
    "        return len(array) - size, len(array)\n",
    "    else:\n",
    "        return idx - size // 2, idx + size // 2\n",
    "\n",
    "def update1(sample_size, th1, th2, n_to_visualize):\n",
    "    th1 *= np.pi\n",
    "    th2 *= np.pi\n",
    "    y_values = np.empty((len(range(sample_size, len(alpha_preliminary_values))), len(turn_sampling)))\n",
    "    x_values = np.empty((len(range(sample_size, len(alpha_preliminary_values)))))\n",
    "    x_err_values = np.empty((len(range(sample_size, len(alpha_preliminary_values)))))\n",
    "\n",
    "    th1_min, th1_max = take_sample(theta1_values, th1, sample_size)\n",
    "    th2_min, th2_max = take_sample(theta2_values, th2, sample_size)\n",
    "    theta1_sample = theta1_values[th1_min : th1_max]\n",
    "    theta2_sample = theta1_values[th2_min : th2_max]\n",
    "\n",
    "    mod_radiuses = np.power(radiuses, 4)[:, th1_min : th1_max, th2_min : th2_max]\n",
    "    mod_radiuses = integrate.simps(mod_radiuses, x=theta1_sample, axis=1)\n",
    "    mod_radiuses = integrate.simps(mod_radiuses, x=theta2_sample, axis=1)\n",
    "    \n",
    "    DA_whole = (\n",
    "        np.power(\n",
    "            mod_radiuses / (\n",
    "                (theta1_sample[-1] - theta1_sample[0]) \n",
    "                * (theta2_sample[-1] - theta2_sample[0])),\n",
    "            1/4\n",
    "        )\n",
    "    )\n",
    "\n",
    "    for i, a_max in enumerate(range(sample_size, len(alpha_preliminary_values))):\n",
    "        a_min = a_max - sample_size\n",
    "        alpha_sample = alpha_preliminary_values[a_min : a_max]\n",
    "        a_mid = (alpha_values[a_min] + alpha_values[a_max]) / 2\n",
    "        \n",
    "        s_radiuses = mod_radiuses[a_min : a_max]\n",
    "        s_radiuses = integrate.simps(s_radiuses, x=alpha_sample, axis=0)\n",
    "\n",
    "        DA = (\n",
    "            np.power(\n",
    "                s_radiuses / (\n",
    "                    (alpha_sample[-1] - alpha_sample[0]) \n",
    "                    * (theta1_sample[-1] - theta1_sample[0]) \n",
    "                    * (theta2_sample[-1] - theta2_sample[0])),\n",
    "                1/4\n",
    "            )\n",
    "        )\n",
    "        y_values[i] = DA\n",
    "        x_values[i] = a_mid\n",
    "        x_err_values[i] = a_mid - alpha_values[a_min]\n",
    "        \n",
    "    y_values = np.asarray(y_values)\n",
    "    y_values = y_values.transpose()\n",
    "    x_values = np.asarray(x_values)\n",
    "    ax.clear()\n",
    "    for i in np.unique(np.logspace(0, np.log10(n_turn_samples), n_to_visualize, dtype=np.int)):\n",
    "    #for i in np.linspace(0, n_turn_samples, 5, dtype=np.int, endpoint=False):\n",
    "        if i == n_turn_samples:\n",
    "            i -= 1\n",
    "        value = np.log10(turn_sampling[i] - turn_sampling[-1]) / np.log10(turn_sampling[0] - turn_sampling[-1])\n",
    "        # whole stuff (integrated only over thetas)\n",
    "        ax.plot(alpha_values, DA_whole[:, i], c=cmap(value), linewidth=0.5, alpha=0.8)\n",
    "        # points\n",
    "        ax.errorbar(x_values, y_values[i], xerr=(x_err_values), linewidth=0, elinewidth=0.5, c=cmap(value), capsize=0.5, capthick=0.5, marker=\"*\", markeredgecolor=\"grey\")\n",
    "    ax.set_xlabel(\"$\\\\alpha$\")\n",
    "    ax.set_ylabel(\"Measured $DA$ in sample\")\n",
    "    ax.set_title(\"DA evolution over $\\\\alpha$ for a moving average of ${}^3$ elements (total is ${}^3$)\\nThis implies {} DA computations over the given $\\\\theta_1, \\\\theta_2$ slice.\\n$\\\\theta$ slice considered: $(\\\\theta_1 = {:.2f}\\\\pi, \\\\theta_2 = {:.2f}\\\\pi)$\".format(sample_size, baseline_samples, baseline_samples - sample_size, th1/np.pi, th2/np.pi, baseline_samples))\n",
    "    #ax.set_ylim(np.min(radiuses), np.max(radiuses))\n",
    "    ax.set_xlim(0.0, np.pi / 2.0)\n",
    "    ax.xaxis.set_major_formatter(\n",
    "        ticker.FuncFormatter(\n",
    "            lambda x, pos: (\"$\\\\frac{{{}}}{{{}}}$\".format(int(x/(np.pi/8)) // gcd(8, int(x/(np.pi/8))), 8 // gcd(8, int(x/(np.pi/8)))) if x != 0 else \"0\") + \"$\\\\pi$\"\n",
    "        )\n",
    "    )\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(base=np.pi/8))\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "a=widgets.IntSlider(value=4, min=2, max=baseline_samples - 4, step=2, continuous_update=False)\n",
    "b=widgets.FloatSlider(value=1, min=0, max=2 + 0.01, step=0.01, continuous_update=False)\n",
    "c=widgets.FloatSlider(value=1, min=0, max=2 + 0.01, step=0.01, continuous_update=False)\n",
    "d=widgets.IntSlider(value=2, min=2, max=n_turn_samples, step=1, continuous_update=False)\n",
    "ui = widgets.VBox([\n",
    "    widgets.Label(\"Number of turn samples to visualize\"), d,\n",
    "    widgets.Label(\"Size of the cubic sample\"), a,\n",
    "    widgets.Label(\"$\\\\theta_1$ value $[\\\\pi$ units$]$\"), b,\n",
    "    widgets.Label(\"$\\\\theta_2$ value $[\\\\pi$ units$]$\"), c])\n",
    "    \n",
    "out = widgets.interactive_output(\n",
    "    update1,\n",
    "    {\"sample_size\":a, \"th1\":b, \"th2\":c, \"n_to_visualize\":d}\n",
    ")\n",
    "\n",
    "display(ui, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A few notes on how to read the plot above\n",
    "* On the sampling of the $\\alpha$ angle: since in our 4D polar coordinates we have a non unitary jacobian for the $\\alpha$ variable, the sampling over $\\alpha$ was performed not uniformely, but it is balanced over the jacobian value (i.e. we sampled uniformely over the variable $y = \\cos 2\\alpha$, for $y \\in [-1,1]$), so that the amount of information obtained is maximized.\n",
    "* The continuous lines you see in the background of the plot are the average radial values computed for the corresponding $\\alpha$ angle and a sample of sample_sizeXsample_size dimension centered on the corresponding $\\theta_1, \\theta_2$ angles chosen.\n",
    "* The horizontal lines with dots represent an averaging integration over the corresponding $\\alpha$ interval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DA fittings and beam loss comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2\n",
    "\n",
    "$$D(N) = \\rho_\\ast \\left(\\frac{\\kappa}{2e}\\right)^\\kappa \\frac{1}{\\ln^\\kappa\\frac{N}{N_0}}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_2(x, rho, n0, k):\n",
    "    return rho * np.power(k / (2 * np.exp(1)), k) / (np.power(np.log(x / n0), k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/data_from_fits.pkl\", 'rb') as f:\n",
    "    turn_sampling, DA, _, real_selected_pars_2, real_selected_co_pars_2, real_selected_k_2, dk = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cee0f143b11448bfb0b1a7801e575ec7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'LHC DA evolution and fitting model 2')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig1, ax1 = plt.subplots()\n",
    "skipper=40\n",
    "ax1.plot(turn_sampling[:-skipper], DA[:-skipper], label=\"DA\")\n",
    "ax1.plot(turn_sampling[:-skipper], model_2(turn_sampling, real_selected_pars_2[0], real_selected_pars_2[1], real_selected_k_2)[:-skipper], label=\"Model 2\\n$\\\\kappa = {:.4f},\\\\rho_\\\\ast = {:.4f}, N_0={:.4f}$\".format(real_selected_k_2, real_selected_pars_2[0], real_selected_pars_2[1]), c=\"C1\")\n",
    "\n",
    "ax1.legend()\n",
    "ax1.set_xlabel(\"$N$ turns\")\n",
    "ax1.set_ylabel(\"$DA(N)$ [$\\\\sigma$ units]\")\n",
    "ax1.set_title(\"LHC DA evolution and fitting model 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
